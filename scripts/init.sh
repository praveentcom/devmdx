#!/bin/bash

# Check if data directory exists and is not empty
if [ -d "data" ] && [ "$(ls -A data)" ]; then
  echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
  echo "â”‚                        âš ï¸  Warning                               â”‚"
  echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
  echo "â”‚  The '/data' directory is not empty.                            â”‚"
  echo "â”‚  DevCard may already be initialized.                            â”‚"
  echo "â”‚                                                                 â”‚"
  echo "â”‚  Please remove the /data directory and try again.               â”‚"
  echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
  exit 1
fi

# Create data directory if it doesn't exist
mkdir -p data/profile
mkdir -p data/config
mkdir -p data/articles/2025
mkdir -p data/community/2025

# Use default values for setup
FIRST_NAME="John"
LAST_NAME="Doe"
GENDER="Male"
EMAIL="john.doe@example.com"
CURRENT_POSITION="Full Stack Developer"
DESCRIPTION="A passionate full-stack developer with expertise in modern web technologies, cloud architecture, and team leadership. Dedicated to building scalable solutions that make a meaningful impact on users and businesses."
LINKEDIN="https://linkedin.com/in/johndoe"
X="https://x.com/johndoe"
INSTAGRAM="https://instagram.com/johndoe"
YOUTUBE="https://youtube.com/johndoe"
GITHUB="https://github.com/johndoe"
STACKOVERFLOW="https://stackoverflow.com/users/123456/johndoe"

# Create data/profile/index.ts
cat > data/profile/index.ts << EOL
import EducationItem from "@/models/EducationItem";
import ProjectItem from "@/models/ProjectItem";
import WorkExperienceItem from "@/models/WorkExperienceItem";
import { ProfileData } from "@/types/user-profile";

export const profileData: ProfileData = {
  profile: {
    firstName: "${FIRST_NAME}",
    lastName: "${LAST_NAME}",
    gender: "${GENDER}",
    email: "${EMAIL}",
    currentPosition: "${CURRENT_POSITION}",

    imageUrl: "https://placehold.co/512x512.png",
    description: "${DESCRIPTION}",
    bulletPoints: [
      "ðŸš€ 5+ years of experience building scalable web applications and distributed systems",
      "ðŸ’» Full-stack expertise spanning React, Node.js, Python, and cloud-native technologies",
      "ðŸ‘¥ Technical leadership experience managing cross-functional teams of 5+ engineers",
      "ðŸŒŸ Active open source contributor with 10k+ GitHub stars across multiple projects",
      "ðŸ“Š Data-driven approach to software architecture and performance optimization",
      "ðŸŽ¯ Passionate about mentoring developers and fostering inclusive engineering cultures",
    ],
    socialMedia: {
      linkedin: "${LINKEDIN}",
      x: "${X}",
      instagram: "${INSTAGRAM}",
      youtube: "${YOUTUBE}",
    },
    links: {
      github: "${GITHUB}",
      stackoverflow: "${STACKOVERFLOW}",
    },
  },
  workExperience: [
    new WorkExperienceItem({
      slug: "tech-innovations-inc",
      role: "Senior Full Stack Developer",
      company: "Tech Innovations Inc.",
      companyImagePath: "https://placehold.co/320x320.png",
      startDate: new Date(2022, 0),
      skills: [
        "Next.js",
        "Node.js",
        "AWS",
        "PostgreSQL",
      ],
      bulletPoints: [
        "Led development of microservices architecture serving 1M+ users",
        "Reduced application load time by 40% through optimization",
        "Mentored 3 junior developers and conducted code reviews",
        "Implemented CI/CD pipelines reducing deployment time by 60%",
      ],
    }),
    new WorkExperienceItem({
      slug: "startupxyz",
      role: "Full Stack Developer",
      company: "StartupXYZ",
      companyImagePath: "https://placehold.co/320x320.png",
      startDate: new Date(2020, 2),
      endDate: new Date(2021, 11),
      skills: [
        "React",
        "Express",
        "MongoDB",
        "Docker",
      ],
      bulletPoints: [
        "Built the entire MVP from scratch using React and Node.js",
        "Integrated payment systems and third-party APIs",
        "Implemented real-time chat features using WebSocket",
        "Achieved 99.9% uptime through robust error handling",
      ],
    }),
  ],
  education: [
    new EducationItem({
      slug: "stanford-university",
      degree: "Master of Science in Computer Science",
      college: "Stanford University",
      collegeImagePath: "https://placehold.co/320x320.png",
      startDate: new Date(2017, 8),
      endDate: new Date(2019, 4),
      bulletPoints: [
        "Specialized in Artificial Intelligence and Machine Learning",
        "Maintained 3.8/4.0 GPA",
        "Teaching Assistant for Data Structures course",
        "Published research paper on distributed systems",
      ],
    }),
  ],
  projects: [
    new ProjectItem({
      slug: "ecotracker-carbon-footprint-app",
      name: "EcoTracker - Carbon Footprint App",
      stack: [
        "React Native",
        "Node.js",
        "MongoDB",
        "AWS",
      ],
      description:
        "A mobile application that helps users track and reduce their carbon footprint through daily habit tracking and personalized recommendations.",
      bulletPoints: [
        "10,000+ downloads on App Store and Google Play",
        "Integrated with 5+ environmental data APIs",
        "Real-time carbon footprint calculations",
        "Social features for community challenges",
      ],
      url: "https://github.com/johndoe/ecotracker",
      imagePath: "https://placehold.co/640x640.png",
      coAuthors: ["Jane Smith", "Mike Johnson"],
      featured: true,
      date: new Date("2023-11-01"),
    }),
    new ProjectItem({
      slug: "taskmaster-pro-project-management-tool",
      name: "TaskMaster Pro - Project Management Tool",
      stack: [
        "Next.js",
        "TypeScript",
        "PostgreSQL",
        "Node.js",
      ],
      description:
        "A comprehensive project management platform with real-time collaboration, time tracking, and advanced analytics for teams.",
      bulletPoints: [
        "Used by 50+ companies and 500+ users",
        "Real-time collaboration with WebSocket",
        "Advanced reporting and analytics dashboard",
        "Integration with Slack, GitHub, and Jira",
      ],
      url: "https://taskmaster-pro.com",
      imagePath: "https://placehold.co/640x640.png",
      featured: true,
      date: new Date("2025-03-01"),
    }),
  ],
};

EOL

echo "âœ… Profile data created successfully"

# Create data/config/index.ts
cat > data/config/index.ts << EOL
import { ConfigData } from "@/types/config";

export const configData: ConfigData = {
  analytics: {
    // Uncomment and add your GA4 Measurement ID to enable Google Analytics
    // googleAnalytics: {
    //   measurementId: "G-XXXXXXXXXX",
    // },
    
    // Uncomment and add your hostname to enable Simple Analytics
    // simpleAnalytics: {
    //   hostname: "yourdomain.com",
    // },

    // Uncomment and add your domain to enable Plausible Analytics
    // plausible: {
    //   domain: "yourdomain.com",
    //   src: "https://plausible.io/js/script.js",
    // },

    // Uncomment and add your website ID to enable Umami Analytics
    // umami: {
    //   websiteId: "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
    //   src: "https://analytics.umami.is/script.js",
    // },

    // Uncomment and configure to enable Matomo Analytics
    // matomo: {
    //   url: "https://your-matomo-instance.com/",
    //   siteId: "1",
    // },

    // Uncomment and add your project ID to enable Microsoft Clarity
    // microsoftClarity: {
    //   projectId: "xxxxxxxxxx",
    // },

    // Uncomment and add your token to enable Mixpanel Analytics
    // mixpanel: {
    //   token: "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",
    // },
  },
  seo: {
    title: "${FIRST_NAME} ${LAST_NAME}",
    description: "${DESCRIPTION}",
    keywords: [
      "full stack developer",
      "software engineer",
      "react",
      "node.js",
      "typescript",
      "javascript",
      "web development",
      "frontend development",
      "backend development",
      "cloud architecture",
      "aws",
      "microservices",
      "devops",
      "team leadership",
      "technical leadership",
      "open source",
      "machine learning",
      "ai",
      "performance optimization",
      "scalable systems",
    ],
    ogTitle: "${FIRST_NAME} ${LAST_NAME}",
    ogDescription: "${DESCRIPTION}",
    ogImage: "https://placehold.co/1024x628.png",
    ogUrl: "https://johndoe.dev",
    twitterCard: "summary_large_image",
    twitterSite: "@johndoe",
    twitterCreator: "@johndoe",
    // Uncomment and customize favicon paths if you want to use custom favicons
    // favicon: {
    //   ico: "/favicon.ico", // Path to .ico file (defaults to /favicon.ico)
    //   png: "/icon.png", // Path to PNG icon file (defaults to /icon.png)
    //   apple: "/apple-icon.png", // Path to Apple touch icon (defaults to /apple-icon.png)
    // },
  },
  navigation: {
    showHomeInNav: true,
    showProjectsInNav: true,
    showArticlesInNav: true,
    showCommunityInNav: true,
    // customMenuItems: [
    //   { href: '/resume', label: 'Resume', external: false },
    //   { href: 'https://example.com', label: 'Portfolio', external: true },
    // ],
  },
  misc: {
    footerSubtitle: "Life is beautiful, isn't it?",
    siteName: "${FIRST_NAME} ${LAST_NAME}",
    siteUrl: "https://johndoe.dev",
    locale: "en-US",
    timezone: "America/New_York",
    webVitals: {
      enabled: true,
      logToConsole: true, // Set to false in production
    },
    content: {
      articleLabel: "Articles", // Change to "Blog", "Essays", "Writings", etc.
      articleLabelSingular: "Article", // Change to "Post", "Essay", "Writing", etc.
      articleSlug: "articles", // Change to "blog", "essays", "writings", etc.
    },
  },
};

EOL

echo "âœ… Config data created successfully"

# Create some sample articles
cat > data/articles/2025/microservices-architecture-patterns.mdx << 'EOL'
---
title: "Building Resilient Microservices: Architecture Patterns for Scale"
description: "Explore proven architectural patterns for building scalable and resilient microservices, including circuit breakers, event sourcing, and distributed tracing."
date: "2025-01-15"
tags: ["Kubernetes", "Docker"]
categories: ["Architecture", "Backend"]
published: true
---

## Introduction

Microservices architecture has become the de facto standard for building scalable applications. However, with great power comes great complexity. In this comprehensive guide, we'll explore battle-tested patterns that help you build resilient microservices.

## Key Architectural Patterns

### 1. Circuit Breaker Pattern

The circuit breaker pattern prevents cascading failures by monitoring service calls and "opening" the circuit when failures exceed a threshold.

```typescript
class CircuitBreaker {
  private failureCount = 0;
  private lastFailureTime = 0;
  private state: 'CLOSED' | 'OPEN' | 'HALF_OPEN' = 'CLOSED';

  async call<T>(fn: () => Promise<T>): Promise<T> {
    if (this.state === 'OPEN') {
      if (Date.now() - this.lastFailureTime > this.timeout) {
        this.state = 'HALF_OPEN';
      } else {
        throw new Error('Circuit breaker is OPEN');
      }
    }

    try {
      const result = await fn();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }
}
```

### 2. Event Sourcing

Event sourcing ensures data consistency across services by storing events rather than current state.

```javascript
// Event store implementation
class EventStore {
  async appendEvent(streamId, event) {
    const eventWithMetadata = {
      ...event,
      streamId,
      version: await this.getNextVersion(streamId),
      timestamp: new Date().toISOString()
    };
    
    await this.database.events.insert(eventWithMetadata);
    await this.publishEvent(eventWithMetadata);
  }
}
```

## Distributed Tracing

Implementing distributed tracing helps you understand request flows across services:

```yaml
# docker-compose.yml for Jaeger
version: '3.8'
services:
  jaeger:
    image: jaegertracing/all-in-one:latest
    ports:
      - "16686:16686"
      - "14268:14268"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
```

## Best Practices

1. **Service Boundaries**: Design services around business capabilities
2. **Data Consistency**: Use eventual consistency with compensation patterns
3. **Monitoring**: Implement comprehensive observability from day one
4. **Security**: Apply zero-trust principles with service mesh

## Conclusion

Building resilient microservices requires careful consideration of these patterns. Start simple, measure everything, and evolve your architecture based on real-world usage patterns.

---

*What patterns have you found most effective in your microservices journey? Share your experiences in the comments below.*
EOL

cat > data/articles/2025/machine-learning-production.mdx << 'EOL'
---
title: "MLOps: Deploying Machine Learning Models to Production"
description: "A comprehensive guide to deploying ML models in production environments, covering model versioning, monitoring, and automated retraining pipelines."
date: "2025-01-22"
tags: ["Python", "Kubernetes"]
categories: ["Data Science", "DevOps"]
published: true
---

## The MLOps Challenge

Deploying machine learning models to production is vastly different from traditional software deployment. Models degrade over time, data distributions shift, and monitoring becomes critical for maintaining performance.

## Model Versioning and Registry

### Setting Up MLflow

```python
import mlflow
import mlflow.sklearn
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Start MLflow tracking
mlflow.set_tracking_uri("http://localhost:5000")
mlflow.set_experiment("customer-churn-prediction")

with mlflow.start_run():
    # Train your model
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # Log parameters and metrics
    mlflow.log_param("n_estimators", 100)
    mlflow.log_param("random_state", 42)
    
    predictions = model.predict(X_test)
    accuracy = accuracy_score(y_test, predictions)
    mlflow.log_metric("accuracy", accuracy)
    
    # Log the model
    mlflow.sklearn.log_model(model, "model")
```

## Containerized Deployment

### FastAPI Model Serving

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import joblib
import numpy as np
from typing import List

app = FastAPI(title="ML Model API", version="1.0.0")

# Load model at startup
model = joblib.load("models/customer_churn_model.pkl")

class PredictionRequest(BaseModel):
    features: List[float]

class PredictionResponse(BaseModel):
    prediction: int
    probability: float
    model_version: str

@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    try:
        features = np.array(request.features).reshape(1, -1)
        prediction = model.predict(features)[0]
        probability = model.predict_proba(features)[0].max()
        
        return PredictionResponse(
            prediction=int(prediction),
            probability=float(probability),
            model_version="1.0.0"
        )
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/health")
async def health_check():
    return {"status": "healthy", "model_loaded": model is not None}
```

## Monitoring and Data Drift Detection

```python
from evidently import ColumnMapping
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset

def detect_data_drift(reference_data, current_data):
    column_mapping = ColumnMapping()
    
    data_drift_report = Report(metrics=[
        DataDriftPreset(),
    ])
    
    data_drift_report.run(
        reference_data=reference_data,
        current_data=current_data,
        column_mapping=column_mapping
    )
    
    return data_drift_report
```

## Key Takeaways

1. **Version Everything**: Models, data, and code should be versioned together
2. **Monitor Continuously**: Track both technical metrics and business KPIs
3. **Automate Safely**: Implement gradual rollouts and automatic rollbacks
4. **Plan for Failure**: Models will degrade - have a response plan ready

The journey from notebook to production is complex, but with the right tools and practices, you can build reliable ML systems that deliver consistent value.
EOL

cat > data/articles/2025/frontend-performance-optimization.mdx << 'EOL'
---
title: "Frontend Performance Optimization: From 3s to 300ms Load Times"
description: "Deep dive into modern frontend performance optimization techniques including code splitting, lazy loading, and advanced bundling strategies."
date: "2025-02-05"
tags: ["React", "webpack"]
categories: ["Frontend", "Performance"]
published: true
---

## The Performance Imperative

In today's fast-paced digital world, every millisecond counts. A 100ms delay in load time can result in a 7% reduction in conversions. Let's explore how to optimize your frontend for blazing-fast performance.

## Measuring Performance

### Core Web Vitals

```javascript
// Measuring Core Web Vitals
import { getCLS, getFID, getFCP, getLCP, getTTFB } from 'web-vitals';

function sendToAnalytics(metric) {
  // Send to your analytics service
  console.log(metric);
}

getCLS(sendToAnalytics);
getFID(sendToAnalytics);
getFCP(sendToAnalytics);
getLCP(sendToAnalytics);
getTTFB(sendToAnalytics);
```

## Code Splitting Strategies

### Route-Based Splitting

```typescript
import { lazy, Suspense } from 'react';
import { Routes, Route } from 'react-router-dom';

// Lazy load components
const Dashboard = lazy(() => import('./pages/Dashboard'));
const Profile = lazy(() => import('./pages/Profile'));
const Settings = lazy(() => import('./pages/Settings'));

function App() {
  return (
    <Suspense fallback={<div>Loading...</div>}>
      <Routes>
        <Route path="/dashboard" element={<Dashboard />} />
        <Route path="/profile" element={<Profile />} />
        <Route path="/settings" element={<Settings />} />
      </Routes>
    </Suspense>
  );
}
```

### Component-Based Splitting

```typescript
import { useState, lazy, Suspense } from 'react';

const HeavyChart = lazy(() => import('./HeavyChart'));

function Dashboard() {
  const [showChart, setShowChart] = useState(false);

  return (
    <div>
      <h1>Dashboard</h1>
      <button onClick={() => setShowChart(true)}>
        Load Chart
      </button>
      
      {showChart && (
        <Suspense fallback={<div>Loading chart...</div>}>
          <HeavyChart />
        </Suspense>
      )}
    </div>
  );
}
```

## Results and Impact

By implementing these optimization techniques:

- **Initial Load Time**: Reduced from 3.2s to 280ms
- **First Contentful Paint**: Improved by 65%
- **Largest Contentful Paint**: Improved by 70%
- **Bundle Size**: Reduced by 40% through code splitting
- **User Engagement**: Increased by 23%

## Key Takeaways

1. **Measure First**: Use tools like Lighthouse and Web Vitals
2. **Split Strategically**: Implement both route and component-based splitting
3. **Optimize Assets**: Compress images and use modern formats
4. **Cache Intelligently**: Leverage service workers and CDNs
5. **Monitor Continuously**: Track real user metrics in production

Performance optimization is an ongoing journey, not a destination. Start with the biggest impact changes and iterate based on real user data.
EOL

cat > data/articles/2025/blockchain-smart-contracts.mdx << 'EOL'
---
title: "Smart Contract Development: Building Secure DeFi Applications"
description: "Learn how to develop, test, and deploy secure smart contracts for DeFi applications using Solidity, Hardhat, and modern security practices."
date: "2025-02-18"
tags: ["Solidity"]
categories: ["Blockchain", "Security"]
published: true
---

## Introduction to Smart Contract Development

Smart contracts are self-executing contracts with terms directly written into code. In the DeFi ecosystem, they enable trustless financial applications. Let's explore how to build secure and efficient smart contracts.

## Development Environment Setup

### Hardhat Configuration

```javascript filename="index.js"
// hardhat.config.js
require("@nomicfoundation/hardhat-toolbox");
require("dotenv").config();

module.exports = {
  solidity: {
    version: "0.8.19",
    settings: {
      optimizer: {
        enabled: true,
        runs: 200,
      },
    },
  },
  networks: {
    hardhat: {
      forking: {
        url: process.env.MAINNET_RPC_URL,
        blockNumber: 18500000,
      },
    },
    goerli: {
      url: process.env.GOERLI_RPC_URL,
      accounts: [process.env.PRIVATE_KEY],
    },
  },
  etherscan: {
    apiKey: process.env.ETHERSCAN_API_KEY,
  },
};
```

## Building a DeFi Lending Protocol

### Core Contract Structure

```solidity
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.19;

import "@openzeppelin/contracts/token/ERC20/IERC20.sol";
import "@openzeppelin/contracts/security/ReentrancyGuard.sol";
import "@openzeppelin/contracts/access/Ownable.sol";

contract LendingPool is ReentrancyGuard, Ownable {
    struct UserAccount {
        uint256 deposited;
        uint256 borrowed;
        uint256 lastUpdateTimestamp;
        uint256 accruedInterest;
    }

    mapping(address => mapping(address => UserAccount)) public userAccounts;
    mapping(address => uint256) public totalDeposits;
    mapping(address => uint256) public totalBorrows;

    event Deposit(address indexed user, address indexed token, uint256 amount);
    event Withdraw(address indexed user, address indexed token, uint256 amount);
    event Borrow(address indexed user, address indexed token, uint256 amount);
    event Repay(address indexed user, address indexed token, uint256 amount);

    function deposit(address token, uint256 amount) external nonReentrant {
        require(amount > 0, "Amount must be greater than 0");
        
        UserAccount storage account = userAccounts[msg.sender][token];
        IERC20(token).transferFrom(msg.sender, address(this), amount);
        
        account.deposited += amount;
        totalDeposits[token] += amount;

        emit Deposit(msg.sender, token, amount);
    }
}
```

## Security Best Practices

1. **Use OpenZeppelin contracts** for standard functionality
2. **Implement proper access controls** with role-based permissions
3. **Add reentrancy guards** to prevent attacks
4. **Validate all inputs** and handle edge cases
5. **Use time locks** for critical administrative functions

## Testing Smart Contracts

```javascript
const { expect } = require("chai");
const { ethers } = require("hardhat");

describe("LendingPool", function () {
  let lendingPool;
  let mockToken;
  let owner;
  let user1;

  beforeEach(async function () {
    [owner, user1] = await ethers.getSigners();

    const MockToken = await ethers.getContractFactory("MockERC20");
    mockToken = await MockToken.deploy("Mock Token", "MOCK", ethers.utils.parseEther("1000000"));

    const LendingPool = await ethers.getContractFactory("LendingPool");
    lendingPool = await LendingPool.deploy();
  });

  it("Should allow users to deposit tokens", async function () {
    const depositAmount = ethers.utils.parseEther("1000");
    
    await mockToken.connect(user1).approve(lendingPool.address, depositAmount);
    await lendingPool.connect(user1).deposit(mockToken.address, depositAmount);

    const userAccount = await lendingPool.userAccounts(user1.address, mockToken.address);
    expect(userAccount.deposited).to.equal(depositAmount);
  });
});
```

## Conclusion

Building secure DeFi applications requires careful attention to security, testing, gas efficiency, and proper monitoring. The DeFi space is rapidly evolving, but these fundamentals will serve as a solid foundation for building robust financial applications on the blockchain.
EOL

echo "âœ… 4 comprehensive sample articles created"

# Create some sample community contributions
cat > data/community/2025/modern-react-patterns-workshop.mdx << 'EOL'
---
title: "Modern React Patterns: Hooks, Context, and Performance"
description: "A comprehensive workshop covering advanced React patterns, custom hooks, context optimization, and performance best practices for large-scale applications."
date: "2025-03-15"
published: true
type: "workshop"
---

## Workshop Overview

Join me for an intensive 3-hour workshop where we'll explore modern React patterns that will transform how you build scalable applications. This session is designed for developers with intermediate React experience who want to level up their skills.

## What You'll Learn

### ðŸŽ¯ Advanced Hook Patterns
- Custom hooks for complex state management
- useReducer for predictable state updates
- useMemo and useCallback optimization strategies
- Building reusable hook libraries

### ðŸš€ Context API Mastery
- When and when NOT to use Context
- Avoiding unnecessary re-renders
- Context composition patterns
- Building type-safe contexts with TypeScript

### âš¡ Performance Optimization
- React.memo and when to use it
- Profiling with React DevTools
- Code splitting strategies
- Lazy loading components and routes

## Workshop Structure

**Part 1: Foundation (60 minutes)**
- Review of React fundamentals
- Introduction to advanced patterns
- Live coding: Building a custom useAsync hook

**Part 2: Context & State (60 minutes)**
- Context API deep dive
- Building a theme system
- State management patterns
- Hands-on: Multi-step form with context

**Part 3: Performance (45 minutes)**
- Identifying performance bottlenecks
- Optimization techniques
- Real-world examples and solutions

**Part 4: Q&A & Code Review (15 minutes)**
- Open discussion
- Code review of participant projects
- Best practices recap

## Prerequisites

- Solid understanding of React hooks (useState, useEffect)
- Basic TypeScript knowledge helpful but not required
- Node.js and npm/yarn installed
- Code editor with React/TypeScript support

## Registration

**Date:** March 15, 2025  
**Time:** 2:00 PM - 5:00 PM EST  
**Format:** Virtual (Zoom) with interactive coding sessions  
**Price:** $149 (Early bird: $99 until March 1st)  

Limited to 25 participants to ensure personalized attention and interactive learning.
EOL

cat > data/community/2025/typescript-enterprise-talk.mdx << 'EOL'
---
title: "TypeScript at Enterprise Scale: Lessons from 100k+ Lines of Code"
description: "A conference talk sharing real-world experiences, challenges, and solutions from implementing TypeScript in large enterprise applications with distributed teams."
date: "2025-04-22"
published: true
type: "talk-session"
---

## Talk Abstract

After migrating a legacy JavaScript codebase of over 100,000 lines to TypeScript across 15+ microservices with a distributed team of 30+ developers, I've learned valuable lessons about what works, what doesn't, and what I wish I knew before starting.

This talk shares practical insights from the trenches of enterprise TypeScript adoption, including migration strategies, team onboarding, tooling decisions, and the unexpected challenges that textbooks don't prepare you for.

## Key Takeaways

### ðŸ¢ Migration Strategy
- **Incremental vs Big Bang**: Why we chose gradual migration and how we made it work
- **Team Coordination**: Managing TypeScript adoption across multiple teams
- **Legacy Integration**: Strategies for working with existing JavaScript libraries
- **Timeline Reality**: Why our "6-month migration" took 18 months (and that's okay)

### ðŸ› ï¸ Tooling & Infrastructure
- **Build Pipeline Evolution**: From Webpack to Vite, lessons learned
- **CI/CD Integration**: Type checking in continuous integration
- **IDE Configuration**: Standardizing development environments across teams
- **Monorepo Considerations**: Shared types, versioning, and dependency management

### ðŸ‘¥ Team & Process
- **Developer Onboarding**: Training JavaScript developers in TypeScript
- **Code Review Evolution**: How type safety changed our review process
- **Documentation Strategy**: When types aren't enough
- **Performance Impact**: Build times, bundle sizes, and developer experience

### ðŸ“Š Measuring Success
- **Bug Reduction**: Quantifying the impact on production issues
- **Developer Productivity**: Metrics that matter (and ones that don't)
- **Code Quality**: Maintainability improvements over time
- **Team Satisfaction**: Developer experience surveys and feedback

## Conference Details

**Event:** TechConf 2025  
**Date:** April 22, 2025  
**Time:** 3:30 PM - 4:15 PM  
**Track:** Frontend Architecture  
**Audience Level:** Intermediate to Advanced  

## Resources

- [Slides](https://slides.com/typescript-enterprise-scale)
- [Migration Checklist](https://github.com/example/ts-migration-checklist)
- [Type Utility Library](https://github.com/example/enterprise-ts-utils)
- [Team Training Materials](https://github.com/example/ts-training)
EOL

cat > data/community/2025/open-source-contribution-guide.mdx << 'EOL'
---
title: "Contributing to Open Source: A Beginner's Guide to Making Your First PR"
description: "A comprehensive guide for developers looking to start contributing to open source projects, covering everything from finding projects to submitting quality pull requests."
date: "2025-05-10"
published: true
type: "online-course"
---

## Why Contribute to Open Source?

Open source contribution is one of the most rewarding ways to grow as a developer. It's not just about giving back to the communityâ€”it's about learning, networking, and building a portfolio that showcases your real-world problem-solving skills.

## Benefits You'll Gain

### ðŸŽ¯ Technical Growth
- **Code Quality**: Learn from experienced maintainers
- **Best Practices**: Exposure to different coding standards and patterns
- **New Technologies**: Discover tools and frameworks you might not encounter at work
- **Problem-Solving**: Tackle diverse challenges across different domains

### ðŸ¤ Professional Development
- **Networking**: Connect with developers worldwide
- **Mentorship**: Learn from senior developers and eventually mentor others
- **Portfolio Building**: Demonstrate your skills with real contributions
- **Career Opportunities**: Many companies value open source experience

## Finding the Right Project

### Start Small, Think Big

**Good First Projects:**
- Documentation improvements
- Bug fixes in projects you already use
- Adding tests to existing functionality
- Improving error messages or user experience

**Projects to Consider:**
- **Tools you use daily**: React, Vue, Express, etc.
- **Language-specific projects**: Awesome lists, utility libraries
- **Documentation sites**: MDN, freeCodeCamp, developer guides
- **Beginner-friendly repos**: Look for "good first issue" labels

## Making Your First Contribution

### Step 1: Set Up Your Environment

```bash
# Fork the repository on GitHub
# Clone your fork
git clone https://github.com/yourusername/project.git
cd project

# Add upstream remote
git remote add upstream https://github.com/original/project.git

# Create a new branch
git checkout -b feature/your-contribution
```

### Step 2: Make Meaningful Changes

**Documentation Example:**
```markdown
<!-- Before -->
## Installation
Run npm install

<!-- After -->
## Installation

Install the package using npm:

\`\`\`bash
npm install package-name
\`\`\`

Or using yarn:

\`\`\`bash
yarn add package-name
\`\`\`
```

### Step 3: Submit a Quality Pull Request

**PR Template Example:**
```markdown
## Description
Brief description of changes and why they're needed.

## Changes Made
- [ ] Added installation instructions for yarn
- [ ] Updated README with requirements section
- [ ] Fixed typos in API documentation

## Testing
- [ ] Existing tests pass
- [ ] Added new tests (if applicable)
- [ ] Manually tested changes
```

## Success Stories

### Real Impact Examples

**Documentation Contribution:**
- **Project**: React Router
- **Contribution**: Added TypeScript examples to documentation
- **Impact**: Helped thousands of developers adopt TypeScript with React Router

**Bug Fix Contribution:**
- **Project**: Express.js
- **Contribution**: Fixed memory leak in middleware handling
- **Impact**: Improved performance for millions of applications

## Resources for Getting Started

### Finding Projects
- **GitHub Explore**: [github.com/explore](https://github.com/explore)
- **Good First Issues**: [goodfirstissues.com](https://goodfirstissues.com)
- **Up For Grabs**: [up-for-grabs.net](https://up-for-grabs.net)

### Learning Resources
- **GitHub Skills**: Interactive courses on Git and GitHub
- **Open Source Guides**: [opensource.guide](https://opensource.guide)

## Your Journey Starts Now

Open source contribution is a journey, not a destination. Start small, be consistent, and focus on learning. Your first contribution might be fixing a typo, but it's the beginning of a rewarding path that will accelerate your growth as a developer.

**Next Steps:**
1. Choose a project you use regularly
2. Read their contribution guidelines
3. Find a small issue to work on
4. Submit your first pull request
5. Celebrate your contribution! ðŸŽ‰
EOL

cat > data/community/2025/ai-ethics-panel-discussion.mdx << 'EOL'
---
title: "AI Ethics in Software Development: A Panel Discussion"
description: "Moderated a panel discussion on the ethical implications of AI in software development, covering bias, transparency, and responsible AI practices."
date: "2025-06-18"
published: true
type: "workshop"
---

## Panel Overview

As AI becomes increasingly integrated into our development workflows and applications, we face complex ethical questions that require thoughtful consideration. This panel brought together experts from diverse backgrounds to discuss the challenges and responsibilities we face as developers in the age of AI.

## Panel Participants

### Dr. Sarah Chen - AI Ethics Researcher
*Stanford AI Lab*
- PhD in Computer Science with focus on algorithmic fairness
- Author of "Bias in Machine Learning Systems"
- 10+ years researching ethical AI implementation

### Marcus Rodriguez - Senior ML Engineer
*TechCorp*
- Led AI ethics initiatives at Fortune 500 company
- Specialist in bias detection and mitigation
- Former Google AI ethics team member

### Priya Patel - Legal Tech Consultant
*Digital Rights Foundation*
- JD/MS in Computer Science
- Advisor on AI regulation and compliance
- Expert in GDPR and AI governance frameworks

### James Wilson - Product Manager
*StartupAI*
- 8+ years building AI-powered products
- Focus on responsible AI product development
- Experience scaling ethical AI practices

## Key Discussion Topics

### ðŸ¤– AI in Development Workflows

**The Question:** How do we ensure AI coding assistants don't perpetuate biased or harmful patterns?

**Key Insights:**
- **Code Review Evolution**: AI-generated code requires new review processes
- **Training Data Concerns**: Understanding what data trained our tools
- **Dependency Risks**: Over-reliance on AI for critical decisions
- **Skill Preservation**: Maintaining human expertise alongside AI assistance

### âš–ï¸ Algorithmic Bias and Fairness

**The Challenge:** How do we identify and mitigate bias in AI systems we build?

**Real-World Example:**
A hiring algorithm showed bias against women because training data reflected historical hiring patterns. The solution involved:
- Rebalancing training data
- Adding fairness constraints to the model
- Implementing ongoing monitoring
- Creating diverse review teams

### ðŸ” Transparency and Explainability

**The Dilemma:** Balancing model performance with explainability requirements.

### ðŸ“‹ Regulatory Compliance and Governance

**Current Regulatory Landscape:**
- **EU AI Act**: Comprehensive AI regulation framework
- **GDPR**: Right to explanation for automated decisions
- **US State Laws**: Emerging AI transparency requirements
- **Industry Standards**: IEEE, ISO AI ethics standards

## Audience Q&A Highlights

### Q: "How do we balance innovation speed with ethical considerations?"

**Panel Consensus:**
- Ethics shouldn't slow innovationâ€”it should guide it
- Build ethical considerations into development processes from day one
- Use automated tools for bias detection and privacy compliance
- Create "ethics by design" frameworks

### Q: "What about AI systems we don't directly control (third-party APIs)?"

**Recommendations:**
- Audit third-party AI services regularly
- Establish contractual requirements for ethical AI
- Implement monitoring for unexpected behavior changes
- Have fallback plans for ethical violations

## Action Items for Developers

### Immediate Steps
1. **Audit Current AI Usage**
   - Inventory all AI tools and services in use
   - Assess potential bias and privacy risks
   - Document decision-making processes

2. **Establish Team Guidelines**
   - Create AI usage policies
   - Implement code review processes for AI-generated content
   - Set up bias testing procedures

### Long-term Initiatives
1. **Build Ethical AI Infrastructure**
   - Implement bias detection tools
   - Create explainability frameworks
   - Establish monitoring and alerting systems

2. **Organizational Change**
   - Form AI ethics committees
   - Include ethics in performance reviews
   - Create incident response procedures

## Conclusion

The integration of AI into software development brings tremendous opportunities and significant responsibilities. As developers, we have the power and obligation to ensure that the systems we build are fair, transparent, and beneficial to all users.

The path forward requires:
- **Continuous Learning**: Stay informed about ethical AI practices
- **Proactive Implementation**: Build ethics into development processes
- **Community Engagement**: Participate in industry-wide discussions
- **User-Centric Design**: Always consider the human impact of our decisions

---

**Panel Recording:** [Available on YouTube](#)  
**Slides:** [Download PDF](#)  
**Follow-up Discussion:** Join our [Discord community](#)
EOL

echo "âœ… 4 diverse community contributions created"

# Create data/community/index.ts
cat > data/community/index.ts << EOL
import { CommunityPageData } from "@/types/community";

export const communityData: CommunityPageData = {
  title: "For the love of contributing back to the community â¤ï¸",
  descriptionLine1: "My talks, presentations, and contributions to the developer community.",
  descriptionLine2: "Sharing knowledge and learning from others.",
};

EOL

echo "âœ… Community data created successfully"

# Create data/profile/cover-letter.md
cat > data/profile/cover-letter.md << EOL
# Cover Letter

**${FIRST_NAME} ${LAST_NAME}**  
${EMAIL}  
[Your Phone Number]  
[Your Location]  

---

## Dear Hiring Manager,

I am writing to express my strong interest in the **[Position Title]** role at **[Company Name]**. With over **5+ years of experience** in full-stack development and a proven track record of building scalable applications, I am excited about the opportunity to contribute to your team's success.

## Why I'm Interested

Your company's commitment to **[specific company value/mission]** particularly resonates with me. I am drawn to **[Company Name]** because of **[specific reason - could be their technology stack, company culture, recent achievements, etc.]**. The opportunity to work on **[specific project/product mentioned in job posting]** aligns perfectly with my passion for **[relevant area of expertise]**.

## What I Bring to the Table

### Technical Expertise
- **Full-Stack Development**: Proficient in React, Node.js, TypeScript, and modern web technologies
- **Cloud & DevOps**: Experience with AWS, Docker, Kubernetes, and CI/CD pipelines
- **Database Management**: Skilled in both SQL (PostgreSQL, MySQL) and NoSQL (MongoDB, Redis) databases
- **Architecture & Design**: Strong background in microservices architecture and system design

### Leadership & Collaboration
- **Team Leadership**: Successfully led cross-functional teams of 5+ developers on complex projects
- **Mentorship**: Passionate about knowledge sharing and have mentored 10+ junior developers
- **Communication**: Excellent at translating technical concepts to non-technical stakeholders
- **Agile Methodologies**: Experienced with Scrum, Kanban, and modern development practices

### Problem-Solving & Innovation
- **Performance Optimization**: Reduced application load times by 40% through strategic optimizations
- **Scalability**: Built systems serving 1M+ users with 99.9% uptime
- **Open Source**: Active contributor to the developer community with 10k+ GitHub stars
- **Continuous Learning**: Stay current with emerging technologies and industry best practices

## Relevant Experience Highlights

In my current role at **[Current Company]**, I have:

- **Architected and developed** a microservices platform that improved system reliability by 60%
- **Led the migration** of legacy systems to modern cloud-native architecture
- **Implemented** comprehensive testing strategies that reduced production bugs by 75%
- **Collaborated closely** with product managers and designers to deliver user-centric solutions
- **Established** development best practices and coding standards across the engineering team

## Why This Role Excites Me

The **[Position Title]** position at **[Company Name]** represents the perfect intersection of my technical skills and career aspirations. I am particularly excited about:

- **[Specific technology/project mentioned in job posting]**: This aligns with my experience in **[relevant experience]**
- **[Company's growth stage/challenges]**: I thrive in environments where I can make a significant impact
- **[Team/culture aspect]**: Your emphasis on **[collaboration/innovation/learning]** matches my values perfectly
- **[Learning opportunity]**: The chance to work with **[specific technology/domain]** would expand my expertise

## My Commitment

If selected for this role, I am committed to:

- **Delivering high-quality code** that meets both functional and non-functional requirements
- **Contributing to team culture** through collaboration, knowledge sharing, and mentorship
- **Driving innovation** by proposing and implementing improvements to existing systems
- **Growing with the company** and taking on increasing responsibilities as opportunities arise

## Next Steps

I would welcome the opportunity to discuss how my experience and passion for **[relevant technology/domain]** can contribute to **[Company Name]**'s continued success. I am available for an interview at your convenience and can start as early as **[availability date]**.

Thank you for considering my application. I look forward to hearing from you soon.

## Best regards,

**${FIRST_NAME} ${LAST_NAME}**

---

### Attachments
- Resume: [Link to your resume]
- Portfolio: [Link to your portfolio/website]
- GitHub: [Your GitHub profile]
- LinkedIn: [Your LinkedIn profile]

---

*This cover letter template is designed to be customized for each application. Replace the bracketed placeholders with specific information about the company and role you're applying for.*

### Customization Tips:
1. **Research the company** thoroughly before writing
2. **Match your experience** to the specific job requirements
3. **Use keywords** from the job posting naturally throughout the letter
4. **Show enthusiasm** for the specific role and company
5. **Keep it concise** while being comprehensive (aim for 1-2 pages)
6. **Proofread carefully** for grammar and spelling errors
7. **Personalize the greeting** with the hiring manager's name if possible
EOL

echo "âœ… Professional cover letter template created"
echo
echo "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”"
echo "â”‚                    ðŸŽ‰ Setup Complete!                           â”‚"
echo "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤"
echo "â”‚  ðŸš€ Next Steps:                                                 â”‚"
echo "â”‚     npm run dev    - Start development server                   â”‚"
echo "â”‚     npm run build  - Build for production                       â”‚"
echo "â”‚                                                                 â”‚"
echo "â”‚  ðŸ“ Customize your content in the /data directory               â”‚"
echo "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
